{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harmonization Parameters Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sensor_data(file_prefix, num_sensors=15,api=False):\n",
    "    \n",
    "    if api:\n",
    "        # file_prefix = 'tsi_v3_api/telemetry_outputs/Raw_Edited.csv'\n",
    "        df = pd.read_csv(file_prefix)\n",
    "        # Group by 'model' and create a dictionary of DataFrames\n",
    "        model_dfs = {}\n",
    "        sensor_dataframes = []\n",
    "        for model, group in df.groupby('friendly_name'):\n",
    "            model_dfs[model] = group\n",
    "\n",
    "        rename_dict = {\n",
    "                'PM1.0 (ug/m3)': 'PM 1.0',\n",
    "                'PM2.5 (ug/m3)': 'PM 2.5',\n",
    "                'PM4.0 (ug/m3)': 'PM 4.0',\n",
    "                'PM10 (ug/m3)': 'PM 10',\n",
    "                'PM0.5 NC (#/cm3)': 'NC 0.5',\n",
    "                'PM1.0 NC (#/cm3)': 'NC 1.0',\n",
    "                'PM2.5 NC (#/cm3)': 'NC 2.5',\n",
    "                'PM4.0 NC (#/cm3)': 'NC 4.0',\n",
    "                'PM10 NC (#/cm3)': 'NC 10',\n",
    "                'Typical Particle Size (um)': 'Typical Particle Size',\n",
    "                'Temperature (Celsius)': 'Temperature',\n",
    "                'Relative Humidity (%)': 'Relative Humidity',\n",
    "                'timestamp' : 'Timestamp'\n",
    "        }\n",
    "        # Access individual DataFrames\n",
    "        for keys in model_dfs.keys():\n",
    "            # print(f\"DataFrame for Model {model}:\")\n",
    "            # print(model_df)\n",
    "                \n",
    "            model_dfs[keys] = model_dfs[keys].rename(columns=rename_dict)\n",
    "            # print(\"\\n\")\n",
    "            sensor_dataframes.append(model_dfs[keys])\n",
    "        return sensor_dataframes\n",
    "        \n",
    "    else:\n",
    "        sensor_dataframes = []\n",
    "        for i in range(1, num_sensors + 1):\n",
    "            filename = f'{file_prefix}{i:02d}.csv'\n",
    "            sensor_df = pd.read_csv(filename)\n",
    "            sensor_dataframes.append(sensor_df)\n",
    "        return sensor_dataframes\n",
    "\n",
    "# sensor_dataframes = read_sensor_data('data/Indoor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data from Darrens Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/75048986/way-to-temporarily-change-the-directory-in-python-to-execute-code-without-affect\n",
    "\n",
    "import contextlib\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def new_cd(x):\n",
    "    d = os.getcwd()\n",
    "\n",
    "    # This could raise an exception, but it's probably\n",
    "    # best to let it propagate and let the caller\n",
    "    # deal with it, since they requested x\n",
    "    os.chdir(x)\n",
    "\n",
    "    try:\n",
    "        yield\n",
    "\n",
    "    finally:\n",
    "        # This could also raise an exception, but you *really*\n",
    "        # aren't equipped to figure out what went wrong if the\n",
    "        # old working directory can't be restored.\n",
    "        os.chdir(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token for yg180@duke.edu is ready\n",
      "1   yg180@duke.edu   81442219015   A04\n",
      "2   yg180@duke.edu   81442219024   A03\n",
      "3   yg180@duke.edu   81442219006   A02\n",
      "4   yg180@duke.edu   81442219027   A01\n",
      "5   yg180@duke.edu   81432151061   B09\n",
      "6   yg180@duke.edu   81432220028   B01\n",
      "7   yg180@duke.edu   81432220036   B02\n",
      "8   yg180@duke.edu   81432220034   B03\n",
      "9   yg180@duke.edu   81432220038   B04\n",
      "10   yg180@duke.edu   81432220032   B05\n",
      "11   yg180@duke.edu   81432220027   B07\n",
      "12   yg180@duke.edu   81432220029   B08\n",
      "13   yg180@duke.edu   81432220033   B10\n",
      "14   yg180@duke.edu   81432220040   B11\n",
      "15   yg180@duke.edu   81432220037   B12\n",
      "16   yg180@duke.edu   81432220047   B13\n",
      "17   yg180@duke.edu   81432152020   B14\n",
      "18   yg180@duke.edu   81432151067   B15\n",
      "19   yg180@duke.edu   81432220039   B16\n",
      "20   yg180@duke.edu   81432220043   B17\n",
      "21   yg180@duke.edu   81432151068   B18\n",
      "22   yg180@duke.edu   81432220031   B19\n",
      "23   yg180@duke.edu   81432152001   B21\n",
      "24   yg180@duke.edu   81442245011   A12\n",
      "25   yg180@duke.edu   81442245016   A16\n",
      "26   yg180@duke.edu   81442251020   A05\n",
      "27   yg180@duke.edu   81442251038   A06\n",
      "28   yg180@duke.edu   81442245018   A07\n",
      "29   yg180@duke.edu   81442245014   A08\n",
      "30   yg180@duke.edu   81442245001   A09\n",
      "31   yg180@duke.edu   81442245012   A10\n",
      "32   yg180@duke.edu   81442245010   A11\n",
      "33   yg180@duke.edu   81442241096   A13\n",
      "34   yg180@duke.edu   81442241089   A14\n",
      "35   yg180@duke.edu   81442241099   A15\n",
      "36   yg180@duke.edu   81442245015   A17\n",
      "37   yg180@duke.edu   81442241098   A18\n",
      "38   yg180@duke.edu   81442249001   A19\n",
      "39   yg180@duke.edu   81442246030   A20\n",
      "40   yg180@duke.edu   81442251032   A21\n",
      "41   yg180@duke.edu   81442251019   A22\n",
      "42   yg180@duke.edu   81442251035   A23\n",
      "43   yg180@duke.edu   81442251023   A24\n",
      "44   yg180@duke.edu   81442251007   A25\n",
      "45   yg180@duke.edu   81442251006   A26\n",
      "46   yg180@duke.edu   81442251022   A27\n",
      "47   yg180@duke.edu   81442251017   A28\n",
      "48   yg180@duke.edu   81442251021   A29\n",
      "49   yg180@duke.edu   81442251030   A30\n",
      "50   yg180@duke.edu   81432152031   B20\n",
      "51   yg180@duke.edu   81432220044   B22\n",
      "52   yg180@duke.edu   81432220035   B23\n",
      "53   yg180@duke.edu   81432220041   B24\n",
      "54   yg180@duke.edu   81432152030   B25\n",
      "55   yg180@duke.edu   81432220030   B26\n",
      "56   yg180@duke.edu   81432220042   B27\n",
      "57   yg180@duke.edu   81432220026   B28\n",
      "58   yg180@duke.edu   81442311122   A33\n",
      "59   yg180@duke.edu   81442317004   A34\n",
      "60   yg180@duke.edu   81442313003   A35\n",
      "61   yg180@duke.edu   81442311142   A36\n",
      "62   yg180@duke.edu   81442320009   A37\n",
      "63   yg180@duke.edu   81442311124   A38\n",
      "64   yg180@duke.edu   81442311140   A39\n",
      "65   yg180@duke.edu   81442311119   A40\n",
      "66   yg180@duke.edu   81442317003   A41\n",
      "67   yg180@duke.edu   81442311127   A42\n",
      "Faulty Device\n",
      "Device list is successfully updated.\n",
      "Merged raw csv successfully compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhshah/Desktop/Bergin Group/Kenya-Indoor-Sensors/tsi_v3_api/get_all_raw_data.py:509: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  raw_df['time_delta'] = raw_df.sort_values('timestamp').groupby('serial')['timestamp'].diff().fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0 QA completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhshah/Desktop/Bergin Group/Kenya-Indoor-Sensors/tsi_v3_api/get_all_raw_data.py:509: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  raw_df['time_delta'] = raw_df.sort_values('timestamp').groupby('serial')['timestamp'].diff().fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 1 QA completed\n",
      "Data processing and quality assurance completed.\n"
     ]
    }
   ],
   "source": [
    "from tsi_v3_api.get_all_raw_data import device_list, client_token, main, get_and_flatten_telemetry\n",
    "\n",
    "work_dir = r'tsi_v3_api/'\n",
    "\n",
    "# with os.chdir(work_dir):\n",
    "with new_cd(work_dir):\n",
    "\n",
    "    from tsi_v3_api.get_all_raw_data import device_list, client_token, main, get_and_flatten_telemetry\n",
    "    secrets_PATH = r'account_auth_info/secretsUL.csv'\n",
    "    main(secrets_PATH, days_duration=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add relavant details to secrets\n",
    "\n",
    "# work_dir = r'tsi_v3_api/'\n",
    "# os.chdir(work_dir) \n",
    "# secrets_PATH = r'account_auth_info/secrets.csv'\n",
    "# main(secrets_PATH,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_prefix = 'tsi_v3_api/telemetry_outputs/Raw_Edited.csv'\n",
    "file_prefix = 'tsi_v3_api/telemetry_outputs/Level1.csv'\n",
    "sensor_dataframes = read_sensor_data(file_prefix,api=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensor_dataframes[0].to_csv('tsi_v3_api/telemetry_outputs/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_sensor_data(file_prefix, num_sensors=15):\n",
    "#     sensor_dataframes = []\n",
    "#     for i in range(1, num_sensors + 1):\n",
    "#         filename = f'data/May25-May31/{file_prefix}{i:02d}.csv'\n",
    "#         sensor_df = pd.read_csv(filename)\n",
    "#         sensor_dataframes.append(sensor_df)\n",
    "#     return sensor_dataframes\n",
    "\n",
    "# sensor_dataframes = read_sensor_data('Indoor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_units_dict(df):\n",
    "#     units_dict = {}\n",
    "#     for column in df.columns:\n",
    "#         units_dict[column] = df.loc[0, column]\n",
    "#     return units_dict\n",
    "\n",
    "# units_dict = create_units_dict(sensor_dataframes[0])\n",
    "\n",
    "units_dict = {'Timestamp': 'UTC',\n",
    " 'Timestamp (Local)': 'UTC-05:00',\n",
    " 'PM 1.0': 'ug/m3',\n",
    " 'PM 2.5': 'ug/m3',\n",
    " 'Applied PM 2.5 Custom Calibration Setting - Multiplication Factor': None,\n",
    " 'Applied PM 2.5 Custom Calibration Setting - Offset': None,\n",
    " 'PM 4.0': 'ug/m3',\n",
    " 'PM 10': 'ug/m3',\n",
    " 'Applied PM 10 Custom Calibration Setting - Multiplication Factor': None,\n",
    " 'Applied PM 10 Custom Calibration Setting - Offset': None,\n",
    " 'NC 0.5': '#/cm3',\n",
    " 'NC 1.0': '#/cm3',\n",
    " 'NC 2.5': '#/cm3',\n",
    " 'NC 4.0': '#/cm3',\n",
    " 'NC 10': '#/cm3',\n",
    " 'PM Sensor Error Status': None,\n",
    " 'CO2': 'ppm',\n",
    " 'Applied CO2 Custom Calibration Setting - Multiplication Factor': None,\n",
    " 'Applied CO2 Custom Calibration Setting - Offset': None,\n",
    " 'CO2 Sensor Error Status': None,\n",
    " 'CH2O': 'ppb',\n",
    " 'Applied CH2O Custom Calibration Setting - Multiplication Factor': None,\n",
    " 'Applied CH2O Custom Calibration Setting - Offset': None,\n",
    " 'CH2O Sensor Error Status': None,\n",
    " 'Barometric Pressure': 'inHg',\n",
    " 'Applied Barometric Pressure Custom Calibration Setting - Offset': None,\n",
    " 'Barometric Sensor Error Status': None,\n",
    " 'CO': 'ppm',\n",
    " 'Applied CO Custom Calibration Setting - Multiplication Factor': None,\n",
    " 'Applied CO Custom Calibration Setting - Offset': None,\n",
    " 'CO Sensor Error Status': None,\n",
    " 'SO2': 'ppb',\n",
    " 'Applied SO2 Custom Calibration Setting - Multiplication Factor': None,\n",
    " 'Applied SO2 Custom Calibration Setting - Offset': None,\n",
    " 'SO2 Sensor Error Status': None,\n",
    " 'O3': 'ppb',\n",
    " 'Applied O3 Custom Calibration Setting - Multiplication Factor': None,\n",
    " 'Applied O3 Custom Calibration Setting - Offset': None,\n",
    " 'O3 Sensor Error Status': None,\n",
    " 'NO2': 'ppb',\n",
    " 'Applied NO2 Custom Calibration Setting - Multiplication Factor': None,\n",
    " 'Applied NO2 Custom Calibration Setting - Offset': None,\n",
    " 'NO2 Sensor Error Status': None,\n",
    " 'VOC tVOC measurement': 'mg/m3',\n",
    " 'Applied TVOC Custom Calibration Setting - Multiplication Factor': None,\n",
    " 'Applied TVOC Custom Calibration Setting - Offset': None,\n",
    " 'VOC Ethanol': 'ppb',\n",
    " 'VOC Sensor Error Status': None,\n",
    " 'Temperature': 'Fahrenheit',\n",
    " 'Applied Temperature Custom Calibration Setting - Offset': 'Celsius',\n",
    " 'Relative Humidity': '%',\n",
    " 'Applied Relative Humidity Custom Calibration Setting - Offset': None,\n",
    " 'Temperature/Humidity Sensor Error Status': None,\n",
    " 'Device Status': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['friendly_name','PM 1.0',\n",
    " 'PM 2.5',\n",
    " 'PM 4.0',\n",
    " 'PM 10',\n",
    " 'NC 0.5',\n",
    " 'NC 1.0',\n",
    " 'NC 2.5',\n",
    " 'NC 4.0',\n",
    " 'NC 10',\n",
    " 'Typical Particle Size',\n",
    " 'Temperature',\n",
    " 'Relative Humidity',\n",
    " 'Barometric Pressure',\n",
    " 'CO2','CO',\n",
    " 'VOC tVOC measurement','SO2', 'NO2', 'O3','Timestamp']\n",
    "\n",
    "# df = sensor_dataframes[0][columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in sensor_dataframes:\n",
    "    \n",
    "    df = df[columns_to_keep]\n",
    "    # TODO:  Ethanol is left\n",
    "\n",
    "    # Define the columns you want to map to\n",
    "    desired_columns = [\n",
    "        'friendly_name', 'Timestamp', 'Timestamp (Local)', 'PM 1.0', 'PM 2.5',\n",
    "        'Applied PM 2.5 Custom Calibration Setting - Multiplication Factor',\n",
    "        'Applied PM 2.5 Custom Calibration Setting - Offset', 'PM 4.0', 'PM 10',\n",
    "        'Applied PM 10 Custom Calibration Setting - Multiplication Factor',\n",
    "        'Applied PM 10 Custom Calibration Setting - Offset', 'NC 0.5', 'NC 1.0',\n",
    "        'NC 2.5', 'NC 4.0', 'NC 10', 'PM Sensor Error Status', 'CO2',\n",
    "        'Applied CO2 Custom Calibration Setting - Multiplication Factor',\n",
    "        'Applied CO2 Custom Calibration Setting - Offset', 'CO2 Sensor Error Status',\n",
    "        'CH2O', 'Applied CH2O Custom Calibration Setting - Multiplication Factor',\n",
    "        'Applied CH2O Custom Calibration Setting - Offset', 'CH2O Sensor Error Status',\n",
    "        'Barometric Pressure', 'Applied Barometric Pressure Custom Calibration Setting - Offset',\n",
    "        'Barometric Sensor Error Status', 'CO', 'Applied CO Custom Calibration Setting - Multiplication Factor',\n",
    "        'Applied CO Custom Calibration Setting - Offset', 'CO Sensor Error Status',\n",
    "        'SO2', 'Applied SO2 Custom Calibration Setting - Multiplication Factor',\n",
    "        'Applied SO2 Custom Calibration Setting - Offset', 'SO2 Sensor Error Status',\n",
    "        'O3', 'Applied O3 Custom Calibration Setting - Multiplication Factor',\n",
    "        'Applied O3 Custom Calibration Setting - Offset', 'O3 Sensor Error Status',\n",
    "        'NO2', 'Applied NO2 Custom Calibration Setting - Multiplication Factor',\n",
    "        'Applied NO2 Custom Calibration Setting - Offset', 'NO2 Sensor Error Status',\n",
    "        'VOC tVOC measurement', 'Applied TVOC Custom Calibration Setting - Multiplication Factor',\n",
    "        'Applied TVOC Custom Calibration Setting - Offset', 'VOC Ethanol', 'VOC Sensor Error Status',\n",
    "        'Temperature', 'Applied Temperature Custom Calibration Setting - Offset',\n",
    "        'Relative Humidity', 'Applied Relative Humidity Custom Calibration Setting - Offset',\n",
    "        'Temperature/Humidity Sensor Error Status', 'Device Status'\n",
    "    ]\n",
    "\n",
    "    # Your original list of columns to keep\n",
    "    # columns_present = [\n",
    "    #     'friendly_name','Timestamp','PM 1.0', 'PM 2.5', 'PM 4.0', 'PM 10',\n",
    "    #     'NC 0.5', 'NC 1.0', 'NC 2.5', 'NC 4.0', 'NC 10',\n",
    "    #     'Typical Particle Size', 'Temperature', 'Relative Humidity',\n",
    "    #     'Barometric Pressure', 'CO2', 'VOC tVOC measurement'\n",
    "    # ]\n",
    "\n",
    "    columns_present = ['friendly_name','PM 1.0',\n",
    "    'PM 2.5', 'PM 4.0', 'PM 10', 'NC 0.5', 'NC 1.0', 'NC 2.5', 'NC 4.0', 'NC 10', 'Typical Particle Size',\n",
    "    'Temperature', 'Relative Humidity', 'Barometric Pressure', 'CO2','CO',\n",
    "    'VOC tVOC measurement','SO2', 'NO2', 'O3','Timestamp']\n",
    "\n",
    "    # Create an empty DataFrame based on desired columns\n",
    "    df_new = pd.DataFrame(columns=desired_columns)\n",
    "\n",
    "    # Populate the DataFrame with the columns from columns_to_keep\n",
    "    for col_pres in columns_present:\n",
    "        if col_pres in desired_columns:\n",
    "            df_new[col_pres] = df[col_pres]\n",
    "        else:\n",
    "            df_new[col_pres] = ''\n",
    "\n",
    "    # Create a new DataFrame with the given data\n",
    "    new_row = pd.DataFrame([[None, 'UTC', 'UTC-05:00', 'ug/m3', 'ug/m3', None, None, 'ug/m3',\n",
    "            'ug/m3', None, None, '#/cm3', '#/cm3', '#/cm3', '#/cm3', '#/cm3',\n",
    "            None, 'ppm', None, None, None, 'ppb', None, None, None, 'inHg', None,\n",
    "            None, 'ppm', None, None, None, 'ppb', None, None, None, 'ppb', None, None,\n",
    "            None, 'ppb', None, None, None, 'mg/m3', None, None, 'ppb', None,\n",
    "            'Celsius', 'Celsius', '%', None, None, None]], columns=desired_columns)\n",
    "\n",
    "    # Concatenate the new row with the existing DataFrame (df_new)\n",
    "    df_new = pd.concat([new_row, df_new], ignore_index=True)\n",
    "    # print(df.head())  # Display the first few rows of the DataFrame\n",
    "\n",
    "    df_new = df_new.rename(columns={'friendly_name':'Sensor'})\n",
    "\n",
    "    df_new.to_csv(f'Output/UL2_data/{df.iloc[0,0]}.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOT Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sensor_dataframes(sensor_dataframes):\n",
    "    numeric_columns = ['PM 1.0', 'PM 2.5', 'PM 4.0', 'PM 10',\n",
    "                       'NC 0.5', 'NC 1.0', 'NC 2.5', 'NC 10',\n",
    "                       'CO2', 'Barometric Pressure', 'VOC tVOC measurement',\n",
    "                       'VOC Ethanol', 'Temperature', 'Relative Humidity']\n",
    "    cleaned_dataframes = []\n",
    "    \n",
    "    columns_not_present = list(set(numeric_columns) - set(sensor_dataframes[0].columns.to_list()))\n",
    "    columns_present = [x for x in numeric_columns if x not in columns_not_present]\n",
    "\n",
    "    print(f'Columns not present in the Dataframe: {columns_not_present}')\n",
    "\n",
    "    for sensor_df in sensor_dataframes:\n",
    "        # remove header\n",
    "        sensor_df = sensor_df.iloc[1:]\n",
    "        # Sort by 'Timestamp'\n",
    "        sensor_df = sensor_df.sort_values(by=['Timestamp']).reset_index()\n",
    "        # Change 'Timestamp' to date format\n",
    "        sensor_df['Timestamp'] = pd.to_datetime(sensor_df['Timestamp'])\n",
    "        # Convert specified columns to numeric\n",
    "        set(columns_present) - set(sensor_dataframes[0].columns.to_list())\n",
    "        \n",
    "        sensor_df[columns_present] = sensor_df[columns_present].apply(pd.to_numeric, errors='coerce')\n",
    "        # Append the cleaned DataFrame to the list\n",
    "        cleaned_dataframes.append(sensor_df)\n",
    "    return cleaned_dataframes\n",
    "\n",
    "cleaned_sensor_dataframes = clean_sensor_dataframes(sensor_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_names = ['sensor01', 'sensor02', 'sensor03', 'sensor04', 'sensor05', \n",
    "                'sensor06','sensor07', 'sensor08', 'sensor09', 'sensor10', 'sensor11', \n",
    "                'sensor12','sensor13', 'sensor14', 'sensor15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_path = '/Users/rishabhshah/Desktop/Bergin Group/Kenya-Indoor-Sensors/data_template/Air Assure data example.csv'\n",
    "# import pandas as pd\n",
    "\n",
    "# example_df = pd.read_csv('/Users/rishabhshah/Desktop/Bergin Group/Kenya-Indoor-Sensors/data_template/Air Assure data example.csv')\n",
    "\n",
    "# example_df[0:1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 1 == Level 0 , columnwise only iscapped is extra in Level 1\n",
    "\n",
    "# print(pd.read_csv('/Users/rishabhshah/Desktop/Bergin Group/Kenya-Indoor-Sensors/tsi_v3_api/telemetry_outputs/Raw_Edited.csv').columns.tolist())\n",
    "# print(pd.read_csv('/Users/rishabhshah/Desktop/Bergin Group/Kenya-Indoor-Sensors/tsi_v3_api/telemetry_outputs/Level0.csv').columns.tolist())\n",
    "# print(pd.read_csv('/Users/rishabhshah/Desktop/Bergin Group/Kenya-Indoor-Sensors/tsi_v3_api/telemetry_outputs/Level1.csv').columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define columns to plot\n",
    "# columns_to_plot = ['PM 2.5', 'CO2', 'Barometric Pressure', 'VOC tVOC measurement', 'Temperature', 'Relative Humidity']\n",
    "# columns_not_present = list(set(columns_to_plot) - set(sensor_dataframes[0].columns.to_list()))\n",
    "# working_columns = [x for x in columns_to_plot if x not in columns_not_present]\n",
    "\n",
    "# num_plots_per_row = 2\n",
    "# for sensor_num, df in enumerate(cleaned_sensor_dataframes[:1]):\n",
    "#     num_columns = len(working_columns)\n",
    "#     num_rows = (num_columns + num_plots_per_row - 1) // num_plots_per_row  # Ceiling division\n",
    "#     fig, axs = plt.subplots(num_rows, num_plots_per_row, figsize=(15, 5*num_rows))\n",
    "#     fig.suptitle(f\"Sensor {sensor_num + 1}\", fontsize=16)\n",
    "\n",
    "#     for i, column in enumerate(working_columns):\n",
    "#         row = i // num_plots_per_row\n",
    "#         col = i % num_plots_per_row\n",
    "#         axs[row, col].plot(df['Timestamp'], df[column])\n",
    "#         axs[row, col].set_title(column)\n",
    "#         axs[row, col].set_xlabel('Time')\n",
    "#         axs[row, col].set_ylabel(f'{column} ({units_dict[column]})')\n",
    "#         axs[row, col].grid(True)\n",
    "#         axs[row, col].tick_params(axis='x', rotation=45)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Harmonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# parameters_dir = os.path.join(\"parameters\")\n",
    "\n",
    "# # Apply parameters to each dataframe and each column\n",
    "# for sensor_df in cleaned_sensor_dataframes:\n",
    "#     for column_name in working_columns:\n",
    "#         coefficients_file = os.path.join(parameters_dir, f\"{column_name.lower().replace(' ', '_')}_coefficients_df.csv\")\n",
    "#         coefficients_df = pd.read_csv(coefficients_file)\n",
    "#         for index, row in coefficients_df.iterrows():\n",
    "#             sensor_df[column_name] = sensor_df[column_name] * row['Coefficient'] + row['Intercept']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define columns to plot\n",
    "# # columns_to_plot = ['PM 2.5', 'CO2', 'Barometric Pressure', 'VOC tVOC measurement', 'Temperature', 'Relative Humidity']\n",
    "\n",
    "# num_plots_per_row = 2\n",
    "# for sensor_num, df in enumerate(cleaned_sensor_dataframes):\n",
    "#     num_columns = len(working_columns)\n",
    "#     num_rows = (num_columns + num_plots_per_row - 1) // num_plots_per_row  # Ceiling division\n",
    "#     fig, axs = plt.subplots(num_rows, num_plots_per_row, figsize=(15, 5*num_rows))\n",
    "#     fig.suptitle(f\"Sensor {sensor_num + 1}\", fontsize=16)\n",
    "\n",
    "#     for i, column in enumerate(working_columns):\n",
    "#         row = i // num_plots_per_row\n",
    "#         col = i % num_plots_per_row\n",
    "#         axs[row, col].plot(df['Timestamp'], df[column])\n",
    "#         axs[row, col].set_title(column)\n",
    "#         axs[row, col].set_xlabel('Time')\n",
    "#         axs[row, col].set_ylabel(f'{column} ({units_dict[column]})')\n",
    "#         axs[row, col].grid(True)\n",
    "#         axs[row, col].tick_params(axis='x', rotation=45)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f\"Output/Weekly QA-QC/May25-May31/sensor_{sensor_num + 1}.png\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
